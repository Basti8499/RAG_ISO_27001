{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for generating summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.a_preprocess_data import get_documents_from_files \n",
    "from ipynb.fs.defs.a_preprocess_data import split_docs \n",
    "from ipynb.fs.defs.a_preprocess_data import clean_and_process_chunked_documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def generate_summary(doc: str):\n",
    "    \"\"\"\n",
    "    Uses GPT 3.5 Turbo to generate a summary based on a given context.\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(\"\"\"You are a helpful assistant that generates a one sentence summary of for the given context.\"\"\")\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(\"\"\"Generate a summary related to this context. Output exactly one sentence that is a maximum of 30 words. \\n \\n Context: {context}\"\"\")\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    generated_summary = llm(chat_prompt.format_prompt(context=doc).to_messages()).content\n",
    "    \n",
    "    return generated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "\n",
    "def save_summaries(summaries: List[str], path: str):\n",
    "    \"\"\"\n",
    "    Saves the summaries to the specified path.\n",
    "    \"\"\"\n",
    "    file_path = f\"./../../evaluationInput/retrieval_eval/{path}.json\"\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(summaries, json_file)\n",
    "        print(f\"Array saved successfully to {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the array to {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summaries_of_documents(path: str, file_type, all_docs, chunk_size, chunk_overlap):\n",
    "    \"\"\"\n",
    "    Uses the above methods to generated summaries for all specified document types and chunk sizes and overlaps.\n",
    "    \"\"\"    \n",
    "    documents = get_documents_from_files(file_type, all_docs)\n",
    "    chunked_documents = split_docs(documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunked_cleaned_documents = clean_and_process_chunked_documents(chunked_documents, False)\n",
    "\n",
    "    documents = []\n",
    "    for doc in chunked_cleaned_documents:\n",
    "        documents.append(doc.page_content)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    try:\n",
    "        with open(f\"./../../evaluationInput/retrieval_eval/{path}.json\", 'r') as json_file:\n",
    "            summaries = json.load(json_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the array from {path}: {e}\")\n",
    "        return\n",
    "\n",
    "    for index, doc in enumerate(documents):\n",
    "        summary = generate_summary(doc)\n",
    "        summaries.append(summary)  \n",
    "\n",
    "        if index % 100 == 0:\n",
    "            save_summaries(summaries, path)    \n",
    "\n",
    "    save_summaries(summaries, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summaries_of_documents(\"summaries_1536_264\", \"All\", True, 1536, 264)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
