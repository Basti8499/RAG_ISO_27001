{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for indexing the data into a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "# Builds the index vector DB from documents with the specified embeddings and collectionName\n",
    "# If it already exists, returns the vector DB\n",
    "\n",
    "\n",
    "def build_or_update_index_vector_db(documents: List[Document], embeddings, collection_name: str, dist_function: str, collection_metadata: dict):\n",
    "    \"\"\"\n",
    "    Creates the vector database with the specified documents and embeddings, if it does not exist yet. Otherwise updates it with them.\n",
    "    \"\"\"\n",
    "    new_client = chromadb.PersistentClient(path=os.environ.get(\"CHROMA_PATH\"))\n",
    "\n",
    "    print(\"Starting to build index for: \")\n",
    "    print(collection_metadata)\n",
    "\n",
    "    # Check if collection already exists\n",
    "    collection_exists = True\n",
    "    try:\n",
    "        new_client.get_collection(collection_name)\n",
    "    except ValueError as e:\n",
    "        collection_exists = False\n",
    "\n",
    "    if not collection_exists:\n",
    "        print(\"Collection is new\")\n",
    "        # If collection does not exist, create it\n",
    "        collection = new_client.create_collection(collection_name)\n",
    "        # Each document needs an ID\n",
    "        ids = [str(i) for i in range(1, len(documents) + 1)]\n",
    "\n",
    "        # Store the text of the document and metadata separately in order to insert it into Chroma\n",
    "        # # The main purpose of this is to reduce calls to paid embedding APIs, otherwise everytime a index is created the embeddings are calculated again\n",
    "        texts = []\n",
    "        metadata_docs = []\n",
    "        for document in documents:\n",
    "            texts.append(document.page_content)\n",
    "            metadata_docs.append(document.metadata)\n",
    "\n",
    "        # Add them in batches (otherwise Chroma error)\n",
    "        for start_idx in range(0, len(embeddings), 1000):\n",
    "            end_idx = start_idx + 1000\n",
    "            # Ensure not to go out of bounds\n",
    "            embeddings_batch = embeddings[start_idx : min(end_idx, len(embeddings))]\n",
    "            texts_batch = texts[start_idx : min(end_idx, len(embeddings))]\n",
    "            ids_batch = ids[start_idx : min(end_idx, len(embeddings))]\n",
    "            metadatas_batch = metadata_docs[start_idx : min(end_idx, len(embeddings))]\n",
    "\n",
    "            # Add embeddings to Chroma\n",
    "            collection.add(embeddings=embeddings_batch, documents=texts_batch, ids=ids_batch, metadatas=metadatas_batch)\n",
    "            print(f\"Added embeddings from {start_idx} to {min(end_idx, len(embeddings))-1}\")\n",
    "\n",
    "        vectordb = Chroma(\n",
    "            client=new_client,\n",
    "            collection_name=collection_name,\n",
    "            collection_metadata={\n",
    "                \"embedding_model_provider\": collection_metadata[\"embedding_model_provider\"],\n",
    "                \"embedding_model_name\": collection_metadata[\"embedding_model_name\"],\n",
    "                \"file_type\": collection_metadata[\"file_type\"],\n",
    "                \"chunk_size\": collection_metadata[\"chunk_size\"],\n",
    "                \"chunk_overlap\": collection_metadata[\"chunk_overlap\"],\n",
    "                \"title_appended\": collection_metadata[\"title_appended\"],\n",
    "                \"hnsw:space\": dist_function,  # either \"l2\" or \"ip\" or \"cosine\"\n",
    "            },\n",
    "        )\n",
    "        print(f\"Collection {collection_name} successfully created.\")\n",
    "        print(\"There are\", vectordb._collection.count(), \"entries in the collection \" + collection_name)\n",
    "\n",
    "        return new_client, vectordb\n",
    "\n",
    "    # If collection exists, update it\n",
    "    else:\n",
    "        print(\"Collection already exists\")\n",
    "        vectordb = Chroma(\n",
    "            client=new_client,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "\n",
    "        collection_count = vectordb._collection.count()\n",
    "        print(\"There are\", collection_count,\n",
    "              \"entries in the collection prior to updating.\" + collection_name)\n",
    "\n",
    "        # Continue the IDs from the last ID\n",
    "        ids = [str(i) for i in range(collection_count + 1,\n",
    "                                     collection_count + len(documents) + 1)]\n",
    "        # Store the text of the document and metadata separately in order to insert it into Chroma\n",
    "        texts = []\n",
    "        metadata_docs = []\n",
    "        for document in documents:\n",
    "            texts.append(document.page_content)\n",
    "            metadata_docs.append(document.metadata)\n",
    "\n",
    "        # Add them in batches (otherwise Chroma error)\n",
    "        for start_idx in range(0, len(embeddings), 1000):\n",
    "            end_idx = start_idx + 1000\n",
    "            # Ensure not to go out of bounds\n",
    "            embeddings_batch = embeddings[start_idx:min(end_idx, len(embeddings))]\n",
    "            texts_batch = texts[start_idx:min(end_idx, len(embeddings))]\n",
    "            ids_batch = ids[start_idx:min(end_idx, len(embeddings))]\n",
    "            metadatas_batch = metadata_docs[start_idx:min(end_idx, len(embeddings))]\n",
    "\n",
    "            # Add embeddings to Chroma\n",
    "            collection.add(embeddings=embeddings_batch, documents=texts_batch, ids=ids_batch, metadatas=metadatas_batch)\n",
    "            print(f\"Added embeddings from {start_idx} to {min(end_idx, len(embeddings))-1}\")\n",
    "\n",
    "        print(\"There are\", vectordb._collection.count(),\n",
    "              \"entries in the collection after updating.\" + collection_name)\n",
    "        \n",
    "        return new_client, vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage._lc_store import create_kv_docstore\n",
    "from langchain.storage.file_system import LocalFileStore\n",
    "from typing import Sequence, Tuple\n",
    "\n",
    "def build_or_update_index_for_parent_child_retriever(parent_documents: Sequence[Tuple[str, Document]], child_documents: List[Document], child_embeddings, collection_name: str, dist_function: str, collection_metadata: dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates the vector database with the specified documents and embeddings in the case of hierarchical retrieval, if it does not exist yet. Otherwise updates it with them.\n",
    "    \"\"\"\n",
    "\n",
    "    new_client = chromadb.PersistentClient(path=os.environ.get(\"CHROMA_PATH\"))\n",
    "\n",
    "    # Check if collection already exists\n",
    "    collection_exists = True\n",
    "    try:\n",
    "        new_client.get_collection(collection_name)\n",
    "    except ValueError as e:\n",
    "        collection_exists = False\n",
    "\n",
    "    if not collection_exists:\n",
    "        # If collection does not exist, create it\n",
    "        collection = new_client.create_collection(collection_name)\n",
    "        # Each document needs an ID\n",
    "        ids = [str(i) for i in range(1, len(child_documents) + 1)]\n",
    "\n",
    "        # Store the text of the document and metadata separately in order to insert it into Chroma\n",
    "        # # The main purpose of this is to reduce calls to paid embedding APIs, otherwise everytime a index is created the embeddings are calculated again\n",
    "        texts = []\n",
    "        metadata_docs = []\n",
    "        for document in child_documents:\n",
    "            texts.append(document.page_content)\n",
    "            metadata_docs.append(document.metadata)\n",
    "\n",
    "        # Add them in batches (otherwise Chroma error)\n",
    "        for start_idx in range(0, len(child_embeddings), 1000):\n",
    "            end_idx = start_idx + 1000\n",
    "            # Ensure not to go out of bounds\n",
    "            embeddings_batch = child_embeddings[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            texts_batch = texts[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            ids_batch = ids[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            metadatas_batch = metadata_docs[start_idx:min(end_idx, len(child_embeddings))]\n",
    "\n",
    "            # Add embeddings to Chroma\n",
    "            collection.add(embeddings=embeddings_batch, documents=texts_batch, ids=ids_batch, metadatas=metadatas_batch)\n",
    "            print(f\"Added embeddings from {start_idx} to {min(end_idx, len(child_embeddings))-1}\")\n",
    "\n",
    "        vectordb = Chroma(\n",
    "            client=new_client,\n",
    "            collection_name=collection_name,\n",
    "            collection_metadata={\n",
    "                \"embedding_model_provider\": collection_metadata[\"embedding_model_provider\"],\n",
    "                \"embedding_model_name\": collection_metadata[\"embedding_model_name\"],\n",
    "                \"file_type\": collection_metadata[\"file_type\"],\n",
    "                \"chunk_size_parent\": collection_metadata[\"chunk_size_parent\"],\n",
    "                \"chunk_overlap_parent\": collection_metadata[\"chunk_overlap_parent\"],\n",
    "                \"chunk_size_child\": collection_metadata[\"chunk_size_child\"],\n",
    "                \"chunk_overlap_child\": collection_metadata[\"chunk_overlap_child\"],\n",
    "                \"title_appended\": collection_metadata[\"title_appended\"],\n",
    "                \"hnsw:space\": dist_function, # either \"l2\" or \"ip\" or \"cosine\"\n",
    "            },\n",
    "        )\n",
    "        print(f\"Collection {collection_name} successfully created.\")\n",
    "        print(\"There are\", vectordb._collection.count(),\n",
    "              \"entries in the collection \" + collection_name)\n",
    "\n",
    "        # Create a local file store for referencing the parent docs.\n",
    "        fs = LocalFileStore(os.environ.get(\"PARENT_DOC_PATH\") + f\"\\\\{collection_name}\")\n",
    "        store = create_kv_docstore(fs)\n",
    "        store.mset(parent_documents)\n",
    "        print(\"Successfully created local file store for parent docs. There are\", len(parent_documents), \"parent documents in the file store.\")\n",
    "\n",
    "        return new_client, vectordb, store\n",
    "\n",
    "    # If collection exists, update it\n",
    "    else:\n",
    "        vectordb = Chroma(\n",
    "            client=new_client,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "\n",
    "        print(\"Collection already exists.\")\n",
    "        collection_count = vectordb._collection.count()\n",
    "        print(\"There are\", collection_count,\n",
    "              \"entries in the collection prior to updating.\" + collection_name)\n",
    "\n",
    "        # Continue the IDs from the last ID\n",
    "        ids = [str(i) for i in range(collection_count + 1,\n",
    "                                     collection_count + len(child_documents) + 1)]\n",
    "        # Store the text of the document and metadata separately in order to insert it into Chroma\n",
    "        texts = []\n",
    "        metadata_docs = []\n",
    "        for document in child_documents:\n",
    "            texts.append(document.page_content)\n",
    "            metadata_docs.append(document.metadata)\n",
    "\n",
    "        # Add them in batches (otherwise Chroma error)\n",
    "        for start_idx in range(0, len(child_embeddings), 1000):\n",
    "            end_idx = start_idx + 1000\n",
    "            # Ensure not to go out of bounds\n",
    "            embeddings_batch = child_embeddings[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            texts_batch = texts[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            ids_batch = ids[start_idx:min(end_idx, len(child_embeddings))]\n",
    "            metadatas_batch = metadata_docs[start_idx:min(end_idx, len(child_embeddings))]\n",
    "\n",
    "            # Add embeddings to Chroma\n",
    "            collection.add(embeddings=embeddings_batch, documents=texts_batch, ids=ids_batch, metadatas=metadatas_batch)\n",
    "            print(f\"Added embeddings from {start_idx} to {min(end_idx, len(child_embeddings))-1}\")\n",
    "\n",
    "        print(\"There are\", vectordb._collection.count(),\n",
    "              \"entries in the collection after updating.\" + collection_name)\n",
    "\n",
    "        # Create a local file store for referencing the parent docs.\n",
    "        fs = LocalFileStore(path=os.environ.get(\"PARENT_DOC_PATH\"))\n",
    "        store = create_kv_docstore(fs)\n",
    "        store.mset(parent_documents)\n",
    "        print(\"Successfully created local file store for parent docs. There are\", len(parent_documents), \"parent documents in the file store.\")\n",
    "\n",
    "        return new_client, vectordb, store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_vector_db(collection_name: str):\n",
    "    \"\"\"\n",
    "    Returns the vector database based on the collection name, if it exists.\n",
    "    \"\"\"\n",
    "    new_client = chromadb.PersistentClient(path=os.environ.get(\"CHROMA_PATH\"))\n",
    "\n",
    "    # Check if collection already exists\n",
    "    collection_exists = True\n",
    "    try:\n",
    "        new_client.get_collection(collection_name)\n",
    "    except ValueError as e:\n",
    "        collection_exists = False\n",
    "\n",
    "    if not collection_exists:\n",
    "        raise Exception(\"Error, raised exception: Collection does not exist.\")\n",
    "    else:\n",
    "        vectordb = Chroma(client=new_client, collection_name=collection_name)\n",
    "\n",
    "        return new_client, vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(collection_name: str):\n",
    "    \"\"\"\n",
    "    Deletes the collection with the given name.\n",
    "    \"\"\"\n",
    "    new_client = chromadb.PersistentClient(path=os.environ.get(\"CHROMA_PATH\"))\n",
    "\n",
    "    try:\n",
    "        new_client.delete_collection(collection_name)\n",
    "    except ValueError as e:\n",
    "        print(\"Collection could not be deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_collections():\n",
    "    \"\"\"\n",
    "    Returns all collections in the local Chroma folder.\n",
    "    \"\"\"\n",
    "    new_client = chromadb.PersistentClient(path=os.environ.get(\"CHROMA_PATH\"))\n",
    "    collections = new_client.list_collections()\n",
    "    return collections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
